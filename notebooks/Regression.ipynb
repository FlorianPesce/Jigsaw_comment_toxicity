{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Untitled42.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re \n",
        "import scipy\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import rankdata\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict\n",
        "\n",
        "import time\n",
        "import scipy.optimize as optimize\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Concatenate\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "outputs": [],
      "metadata": {
        "id": "TGqzLHcAVCns"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "source": [
        "# Ridge Regression\n",
        "def ridge_regression(vec, X, y, X_test, folds, stratified):\n",
        "    skf = StratifiedKFold(n_splits=FOLDS,shuffle=True,random_state=1)\n",
        "    val_scores = []\n",
        "    X_less_toxics = []\n",
        "    X_more_toxics = []\n",
        "\n",
        "    preds = []\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X, stratified)):\n",
        "        X_train, y_train = X[train_index], y[train_index]\n",
        "        model = Ridge()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        X_less_toxic = vec.transform(val_df['less_toxic'])\n",
        "        X_more_toxic = vec.transform(val_df['more_toxic'])\n",
        "\n",
        "        pred_less_toxic = model.predict(X_less_toxic)\n",
        "        pred_more_toxic = model.predict(X_more_toxic)\n",
        "\n",
        "        X_less_toxics.append(pred_less_toxic)\n",
        "        X_more_toxics.append(pred_more_toxic)\n",
        "\n",
        "        # Validation Accuracy\n",
        "        val_acc = (pred_less_toxic < pred_more_toxic).mean()\n",
        "        val_scores.append(val_acc)\n",
        "\n",
        "        pred = model.predict(X_test)\n",
        "        preds.append(pred)\n",
        "\n",
        "        print(f\"FOLD:{fold}, val_acc:{val_acc:.5f}\")\n",
        "\n",
        "    mean_val_acc = np.mean(val_scores)\n",
        "    p1 = np.mean(np.vstack(X_less_toxics), axis=0)\n",
        "    p2 = np.mean( np.vstack(X_more_toxics), axis=0)\n",
        "\n",
        "    preds = np.mean(np.vstack(preds), axis=0)\n",
        "    \n",
        "    return mean_val_acc, preds, p1, p2"
      ],
      "outputs": [],
      "metadata": {
        "id": "ffdR2YWUW9le"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "source": [
        "# Data processing\n",
        "val_df = pd.read_csv(\"/content/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
        "test_df = pd.read_csv(\"/content/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n",
        "ruddit_df = pd.read_csv(\"/content/ruddit.csv\")\n",
        "jigsaw1_train_df = pd.read_csv(\"/content/jigsaw-toxic-classification/train.csv\")\n",
        "print(len(val_df))\n",
        "print(len(test_df))\n",
        "print(len(ruddit_df))\n",
        "print(val_df.head())\n",
        "print(test_df.head())\n",
        "print(ruddit_df.head())\n",
        "print(jigsaw1_train_df.head())\n",
        "\n",
        "\n",
        "ruddit_df['y'] = ruddit_df['offensiveness_score'].map(lambda x: 0.0 if x <=0 else x)\n",
        "print(ruddit_df.head())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30108\n",
            "7537\n",
            "5838\n",
            "   worker  ...                                         more_toxic\n",
            "0     313  ...  WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...\n",
            "1     188  ...   Daphne Guinness \\n\\nTop of the mornin' my fav...\n",
            "2      82  ...  \"Atom you don't believe actual photos of mastu...\n",
            "3     347  ...  You seem to have sand in your vagina.\\n\\nMight...\n",
            "4     539  ...           hey \\n\\nway to support nazis, you racist\n",
            "\n",
            "[5 rows x 3 columns]\n",
            "   comment_id                                               text\n",
            "0      114890  \"\\n \\n\\nGjalexei, you asked about whether ther...\n",
            "1      732895  Looks like be have an abuser , can you please ...\n",
            "2     1139051  I confess to having complete (and apparently b...\n",
            "3     1434512  \"\\n\\nFreud's ideas are certainly much discusse...\n",
            "4     2084821  It is not just you. This is a laundry list of ...\n",
            "  post_id  ... offensiveness_score\n",
            "0  42g75o  ...              -0.083\n",
            "1  42g75o  ...              -0.022\n",
            "2  42g75o  ...               0.167\n",
            "3  42g75o  ...              -0.146\n",
            "4  42g75o  ...              -0.083\n",
            "\n",
            "[5 rows x 5 columns]\n",
            "                 id  ... identity_hate\n",
            "0  0000997932d777bf  ...             0\n",
            "1  000103f0d9cfb60f  ...             0\n",
            "2  000113f07ec002fd  ...             0\n",
            "3  0001b41b1c6bb37e  ...             0\n",
            "4  0001d958c54c6e35  ...             0\n",
            "\n",
            "[5 rows x 8 columns]\n",
            "  post_id comment_id  ... offensiveness_score      y\n",
            "0  42g75o    cza1q49  ...              -0.083  0.000\n",
            "1  42g75o    cza1wdh  ...              -0.022  0.000\n",
            "2  42g75o    cza23qx  ...               0.167  0.167\n",
            "3  42g75o    cza2bw8  ...              -0.146  0.000\n",
            "4  42g75o    cza2iji  ...              -0.083  0.000\n",
            "\n",
            "[5 rows x 6 columns]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "famEe_YaYOf4",
        "outputId": "f970242e-5cc4-44a8-efc4-ee0b84d39bc4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(analyzer='char_wb', max_df=0.5, min_df=3, ngram_range=(4, 6))\n",
        "X = tfidf_vectorizer.fit_transform(ruddit_df['txt'])\n",
        "X_test = tfidf_vectorizer.transform(test_df['text'])\n",
        "#print(X)\n",
        "#print(X_test)\n",
        "\n",
        "stratified = (np.around(ruddit_df[\"y\"].values, decimals = 1)*10).astype(int)\n",
        "FOLDS = 5\n",
        "mean_val_acc, ruddit_predictions, ruddit_p1, ruddit_p2 =  ridge_regression(tfidf_vectorizer, X, ruddit_df[\"y\"].values, X_test, FOLDS, stratified)\n",
        "print(\"Mean accuracy on validaton data\", mean_val_acc)\n",
        "print(\"Predictions on ruddit\", ruddit_predictions)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:0, val_acc:0.64687\n",
            "FOLD:1, val_acc:0.63973\n",
            "FOLD:2, val_acc:0.64671\n",
            "FOLD:3, val_acc:0.65019\n",
            "FOLD:4, val_acc:0.64405\n",
            "Mean accuracy on validaton data 0.6455094991364421\n",
            "Predictions on ruddit [0.12439541 0.12452538 0.08968182 ... 0.18093773 0.48498902 0.1053199 ]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDfI9njNYric",
        "outputId": "3cc2447f-2205-49f8-e48c-87067427833e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "test_df['score'] = ruddit_predictions\n",
        "test_df[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "HpHmLwBOeUoH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "source": [
        "toxic = 1.0\n",
        "severe_toxic = 2.0\n",
        "obscene = 3.0\n",
        "threat = 1.0\n",
        "insult = 1.0\n",
        "identity_hate = 2.0\n",
        "\n",
        "# Creating the dataset from the toxic comment classification challenge\n",
        "# Taking a weighted sum for the different toxic comments categories\n",
        "def create_train_data(df):\n",
        "    df['y'] = df[[\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]].max(axis=1)\n",
        "    df['y'] = df[\"y\"] + df['severe_toxic'] * severe_toxic\n",
        "    df['y'] = df[\"y\"] + df['obscene'] * obscene\n",
        "    df['y'] = df[\"y\"] + df['threat'] * threat\n",
        "    df['y'] = df[\"y\"] + df['insult'] * insult\n",
        "    df['y'] = df[\"y\"] + df['identity_hate'] * identity_hate\n",
        "    \n",
        "    #undersample non toxic comments on Toxic Comment Classification Challenge\n",
        "    min_len = (df['y'] >= 1).sum()\n",
        "    df_y0_undersample = df[df['y'] == 0].sample(n=int(min_len*1.5),random_state=201)\n",
        "    df = pd.concat([df[df['y'] >= 1], df_y0_undersample])\n",
        "                                                \n",
        "    return df\n",
        "\n",
        "print(jigsaw1_train_df.head())\n",
        "\n",
        "jigsaw1_train_df_modified = create_train_data(jigsaw1_train_df)\n",
        "print(jigsaw1_train_df_modified.head())\n",
        "print(jigsaw1_train_df_modified['y'].value_counts())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 id  ...    y\n",
            "0  0000997932d777bf  ...  0.0\n",
            "1  000103f0d9cfb60f  ...  0.0\n",
            "2  000113f07ec002fd  ...  0.0\n",
            "3  0001b41b1c6bb37e  ...  0.0\n",
            "4  0001d958c54c6e35  ...  0.0\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "                  id  ...    y\n",
            "6   0002bcb3da6cb337  ...  7.0\n",
            "12  0005c987bdfc9d4b  ...  1.0\n",
            "16  0007e25b2121310b  ...  1.0\n",
            "42  001810bf8c45bf5f  ...  7.0\n",
            "43  00190820581d90ce  ...  5.0\n",
            "\n",
            "[5 rows x 9 columns]\n",
            "0.0     24337\n",
            "1.0      5666\n",
            "5.0      4001\n",
            "4.0      2269\n",
            "2.0      1651\n",
            "7.0      1629\n",
            "6.0       337\n",
            "9.0       265\n",
            "3.0       250\n",
            "8.0       126\n",
            "10.0       31\n",
            "Name: y, dtype: int64\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcVUKJ7WlUIx",
        "outputId": "5a641336-914d-47c6-891b-11bf9d19194f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "source": [
        "FOLDS = 5\n",
        "\n",
        "vec = TfidfVectorizer(analyzer='char_wb', max_df=0.5, min_df=3, ngram_range=(4, 6))\n",
        "X = vec.fit_transform(jigsaw1_train_df_modified['comment_text'])\n",
        "y = jigsaw1_train_df_modified[\"y\"].values\n",
        "X_test = vec.transform(test_df['text'])\n",
        "\n",
        "stratified = np.around(y)\n",
        "mean_val_acc, jigsaw1_predictions, jigsaw1_p1, jigsaw1_p2 =  ridge_regression(vec, X, y, X_test, FOLDS, stratified)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FOLD:0, val_acc:0.67939\n",
            "FOLD:1, val_acc:0.68052\n",
            "FOLD:2, val_acc:0.67995\n",
            "FOLD:3, val_acc:0.68268\n",
            "FOLD:4, val_acc:0.68251\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QenKuNBL0nye",
        "outputId": "d1b72d45-8a08-4754-d5ba-427d495eccfb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "test_df['score'] = jigsaw1_predictions\n",
        "test_df[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "blkvzWdKMsFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "source": [
        "# Ensemble\n",
        "jigsaw1_max = max(jigsaw1_p1.max() , jigsaw1_p2.max())\n",
        "ruddit_max = max(ruddit_p1.max() , ruddit_p2.max())\n",
        "ensemble_score = jigsaw1_predictions/jigsaw1_max + ruddit_predictions/ruddit_max\n",
        "test_df['score'] = ensemble_score\n",
        "test_df[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "phzooFi7Ikuv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "Tp70oiTZUL4L"
      }
    }
  ]
}